# -*- coding: utf-8 -*-
"""EPC04-GustavoAlves.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bhQHe5MXFj3ZBfGsS9tMPjegRnL_Wmg7

# Atividade Kohonen - Gustavo Alves
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans


# Dados iniciais

dimensao = 4                   
linhas = 20; colunas = 20     #Tamanhos de linhas e Linhas do SOM
alcanceMax = linhas + colunas #Tamanho máximo calculado em linhas + Linhas
n = 0.01                      #Taxa inicial de aprendizagem usada na construção
epocas = 2000                 #Limite máximo de iterações para treinar" o SOM

#Função recebe quee retorna o índice da linha e coluna do SOM, com tamanho das linhas e colunas
#que são as coordenadas da célula do mapa cujo vetor está mais próximo do
#item de dados em data[t], o nó vencendor
def no_mais_proximo(data, t, map, m_Linhas, m_Colunas):
  resultado = (0,0)
  menor_distancia = float ("inf")
  for i in range(m_Linhas):
    for j in range(m_Colunas):
      ed = dist_euclidiana(map[i][j], data[t])
      if ed < menor_distancia:
        menor_distancia = ed
        resultado = (i, j)
  return resultado

def dist_euclidiana(v1, v2):
  return np.linalg.norm(v1 - v2)

def dist_manhattan(r1, c1, r2, c2):
  return np.abs(r1-r2) + np.abs(c1-c2)

#Recebe uma lista de valores de 0 até n e retorna o valor que mais aparece nessa lista
def mais_comum(lista, n):
  if len(lista) == 0: return -1
  contador = np.zeros(shape=n, dtype=np.int)
  for i in range(len(lista)):
    contador[lista[i]] += 1
  return np.argmax(contador)

"""#Treinamento"""

def treinamento():
 
  print("\nCarregando dados Iris para memoria \n")
  arquivo = "iris-10dobscv-1tra.dat"
  dado_x = np.loadtxt(arquivo, delimiter=",", usecols=range(0,4),
    dtype=np.float64,skiprows=9)


  # Construção do SOM
  print("Construindo um SOM 30x30 a partir dos dados Iris")
  #a função random_sample() está gerando uma matriz 30x30 onde cada célula do
  #vetor de tamanho 4 possui valores aleatórios no intervalo [0.0 a 1.0]
  map = np.random.random_sample(size=(linhas,colunas,dimensao))
  for s in range(epocas):
    if s % (epocas/10) == 0: print("iteração = ", str(s))
    #pct_rest calcula a porcentagem de iterações que faltam para concluir, por
    pct_rest = 1.0 - ((s * 1.0) / epocas)
    #alcance_atual é a distancia máxima que as células podem aceitar como próximas
    #uma das outras durante a iterção s.
    alcance_atual = (int)(pct_rest * alcanceMax)
    taxa_atual = pct_rest * n
    
  
    
    t = np.random.randint(len(dado_x))  #t recebe um dado aleatório e o melhor nó é determinado
    (bmu_linha, bmu_coluna) = no_mais_proximo(dado_x, t, map, linhas, colunas) #BMU (best match unit) que é o neurônio que possui a menor distancia
    #entre o conjunto de características do dado e o conjunto de pesos do neurônio dentre todos os neurônios.
    
    #Em seguida cada nó do SOM é examinado. Se o nó atual está próximo ao melhor
    #nó da unidade correspondente, então o vetor do nó atual é atualizado
    for i in range(linhas):
      for j in range(colunas):
        if dist_manhattan(bmu_linha, bmu_coluna, i, j) < alcance_atual:
          #a atualização aproxima o vetor do nó atual do item dos dados atuais 
          #usando o valor taxa_atual que diminui lentamente ao longo do tempo.
          map[i][j] = map[i][j] + taxa_atual * \
(dado_x[t] - map[i][j])
  print("Construção do SOM finalizada \n")

  # Construção da U-Matrix
 
  u_matrix = np.zeros(shape=(linhas,colunas), dtype=np.float64)
  #Inicialmente cada 30x30 célula da U-Matrix possui um valor 0.0. Em seguidacada célula na U-Matrix é processada
  for i in range(linhas):
    for j in range(colunas):
      #v é o vetor no Som que corresponde à célula U-Matrix atual. Cada célula
      #adjacente no SOM(acima, abaixo, esquerda e direita) é processada e a soma das distancias euclidianas é calculada
      v = map[i][j]
      soma_dist = 0.0; cont = 0
     
      if i-1 >= 0:    # acima
        soma_dist += dist_euclidiana(v, map[i-1][j]) 
        cont += 1
      if i+1 <= linhas-1:   # abaixo
        soma_dist += dist_euclidiana(v, map[i+1][j])
        cont += 1
      if j-1 >= 0:   # esquerda
        soma_dist += dist_euclidiana(v, map[i][j-1])
        cont += 1
      if j+1 <= colunas-1:   # direita
        soma_dist += dist_euclidiana(v, map[i][j+1])
        cont += 1
      
      u_matrix[i][j] = soma_dist / cont
  print("U-Matrix construída \n")

  # Um valor muito pequeno em uma célula da U-Matrix significa que a célula
  #correspondente no SOM está muito próxima de seus vizinhos, então as células
  #vizinhas fazem parte de um grupo semelhante.


  plt.imshow(u_matrix, cmap='gray')
  plt.show()

  print("K-means \n")
  mapping = np.empty(shape=(linhas,colunas), dtype=object)
  for i in range(linhas):
    for j in range(colunas):
      mapping[i][j] = []
  map_kmeans = []

  #Criando matriz com vencedor
  for t in range(len(dado_x)):
    (bmu_row, bmu_col) = no_mais_proximo(dado_x,t, map, linhas, colunas)
    mapping[bmu_row][bmu_col].append(1)
    map_kmeans.append([bmu_row, bmu_col])

  map_kmeans = np.array(map_kmeans)
  # Criar o cluster
  cluster = KMeans(n_clusters=3, random_state=0).fit(map_kmeans)

  # Plotar o K-means
  plt.subplot(221)
  plt.scatter(map_kmeans[:, 0], map_kmeans[:, 1], c=cluster.labels_)
  plt.title("K-means")


  return cluster, map,

"""#Teste"""

def teste(desejado, map):
  arquivoTeste = "iris-10dobscv-1tst.dat"
  dado_x= np.loadtxt(arquivoTeste, delimiter=",", usecols=range(0,4),
    dtype=np.float64, skiprows=9)
  map_kmeans = []
  for t in range(len(dado_x)):
      (bmu_row, bmu_col) = no_mais_proximo(dado_x,t, map, linhas, colunas)
      map_kmeans.append([bmu_row, bmu_col])
  map_kmeans = np.array(map_kmeans)
  y_pred = desejado.fit_predict(map_kmeans)

  print('Saída Cluster: ', y_pred)

if __name__=="__main__":
  desejado, map = treinamento()
  teste( desejado, map )